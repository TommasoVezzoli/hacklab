{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00b8052f",
   "metadata": {},
   "source": [
    "# **Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ba1d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e923a7",
   "metadata": {},
   "source": [
    "## **Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee6d7788",
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints = pd.read_excel('EaUgXb.xlsx', index_col = 0)\n",
    "clients = pd.read_excel('btUTgX.xlsx', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3980b33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn = clients['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d6946f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints = complaints.merge(churn, left_on='customerID', right_index=True)\n",
    "complaints.drop(columns=['complaint_number'], inplace=True)\n",
    "complaints.rename(columns={'Churn': 'churn'}, inplace=True)\n",
    "complaints['churn'] = complaints['churn'].map({'No': 0, 'Yes': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "920efade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "churn\n",
       "1    0.617445\n",
       "0    0.382555\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints['churn'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d7d672",
   "metadata": {},
   "source": [
    "The classes are not balanced, the majority of clients who complain then churn. This however is reasonable so we will not try to rebalance the data and leave it like this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26d2c496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# t-SNE to 3D\n",
    "tsne = TSNE(n_components=3, random_state=42)\n",
    "X_embedded = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff63ed4",
   "metadata": {},
   "source": [
    "## **Classifier**\n",
    "Now we build a simple classifier that, based on the complaint, tries to predict whether that client will churn or not. We try the following models:\n",
    "- Logistic Regression\n",
    "- CatBoost\n",
    "- Random Forest\n",
    "- Small Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3914eb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = complaints['churn'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e77162ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7133956386292835\n",
      "Confusion Matrix:\n",
      " [[ 54  69]\n",
      " [ 23 175]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.44      0.54       123\n",
      "           1       0.72      0.88      0.79       198\n",
      "\n",
      "    accuracy                           0.71       321\n",
      "   macro avg       0.71      0.66      0.67       321\n",
      "weighted avg       0.71      0.71      0.70       321\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression(max_iter=1000)\n",
    "log.fit(X_train, y_train)\n",
    "\n",
    "y_pred = log.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7745f7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7227414330218068\n",
      "Confusion Matrix:\n",
      " [[ 62  61]\n",
      " [ 28 170]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.50      0.58       123\n",
      "           1       0.74      0.86      0.79       198\n",
      "\n",
      "    accuracy                           0.72       321\n",
      "   macro avg       0.71      0.68      0.69       321\n",
      "weighted avg       0.72      0.72      0.71       321\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cboost = CatBoostClassifier(verbose=0)  \n",
    "cboost.fit(X_train, y_train)\n",
    "\n",
    "y_pred = cboost.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67340cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7071651090342679\n",
      "Confusion Matrix:\n",
      " [[ 60  63]\n",
      " [ 31 167]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.49      0.56       123\n",
      "           1       0.73      0.84      0.78       198\n",
      "\n",
      "    accuracy                           0.71       321\n",
      "   macro avg       0.69      0.67      0.67       321\n",
      "weighted avg       0.70      0.71      0.70       321\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd2e6162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.6336\n",
      "Epoch [2/20], Loss: 0.5533\n",
      "Epoch [3/20], Loss: 0.4847\n",
      "Epoch [4/20], Loss: 0.5008\n",
      "Epoch [5/20], Loss: 0.4557\n",
      "Epoch [6/20], Loss: 0.4388\n",
      "Epoch [7/20], Loss: 0.4213\n",
      "Epoch [8/20], Loss: 0.4084\n",
      "Epoch [9/20], Loss: 0.4037\n",
      "Epoch [10/20], Loss: 0.3845\n",
      "Epoch [11/20], Loss: 0.3827\n",
      "Epoch [12/20], Loss: 0.3559\n",
      "Epoch [13/20], Loss: 0.3547\n",
      "Epoch [14/20], Loss: 0.3570\n",
      "Epoch [15/20], Loss: 0.3374\n",
      "Epoch [16/20], Loss: 0.3171\n",
      "Epoch [17/20], Loss: 0.3357\n",
      "Epoch [18/20], Loss: 0.3044\n",
      "Epoch [19/20], Loss: 0.3140\n",
      "Epoch [20/20], Loss: 0.2985\n",
      "Accuracy: 0.7507788161993769\n",
      "Confusion Matrix:\n",
      " [[ 81  42]\n",
      " [ 38 160]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.66      0.67       123\n",
      "         1.0       0.79      0.81      0.80       198\n",
      "\n",
      "    accuracy                           0.75       321\n",
      "   macro avg       0.74      0.73      0.73       321\n",
      "weighted avg       0.75      0.75      0.75       321\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Prepare data ---\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# --- Define small neural network ---\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(X_train.shape[1], 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()  \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# --- Train ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = NN().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "n_epochs = 20\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).unsqueeze(1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{n_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# --- Evaluation ---\n",
    "model.eval()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        preds = (outputs.cpu().numpy() > 0.5).astype(int)\n",
    "        y_pred.extend(preds.flatten())\n",
    "        y_true.extend(labels.numpy())\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e3effc",
   "metadata": {},
   "source": [
    "The small neural network is the architecture that has the higher accuracy. However, the Logistic Regression is the one that has lowest false-negative rate. Since we want to have a classifier that, given an unseen complaint, tells us whether the client is likely to churn or not (so that we can intervene), we might choose the most cautious model, i.e. the Logistic Regression. As a matter of fact, in terms of costs for the company, it is much more expensive to lose a client rather than sending him immediate support to prevent him from churn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2049aba4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
